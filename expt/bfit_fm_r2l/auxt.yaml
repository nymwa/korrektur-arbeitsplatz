source: /home/koyama.s/korrektur/start.sh
eval_config: /home/koyama.s/korrektur/arbeitsplatz/expt/r2l_eval_config.bfit_16000.absolute.yaml
data: /home/koyama.s/korrektur/arbeitsplatz/data/bfit/fm_r2l_16000
data_indices:
  - [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255, 260, 265, 270, 275, 280, 285, 290, 295]
  - [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 106, 111, 116, 121, 126, 131, 136, 141, 146, 151, 156, 161, 166, 171, 176, 181, 186, 191, 196, 201, 206, 211, 216, 221, 226, 231, 236, 241, 246, 251, 256, 261, 266, 271, 276, 281, 286, 291, 296]
  - [2, 7, 12, 17, 22, 27, 32, 37, 42, 47, 52, 57, 62, 67, 72, 77, 82, 87, 92, 97, 102, 107, 112, 117, 122, 127, 132, 137, 142, 147, 152, 157, 162, 167, 172, 177, 182, 187, 192, 197, 202, 207, 212, 217, 222, 227, 232, 237, 242, 247, 252, 257, 262, 267, 272, 277, 282, 287, 292, 297]
  - [3, 8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58, 63, 68, 73, 78, 83, 88, 93, 98, 103, 108, 113, 118, 123, 128, 133, 138, 143, 148, 153, 158, 163, 168, 173, 178, 183, 188, 193, 198, 203, 208, 213, 218, 223, 228, 233, 238, 243, 248, 253, 258, 263, 268, 273, 278, 283, 288, 293, 298]
  - [4, 9, 14, 19, 24, 29, 34, 39, 44, 49, 54, 59, 64, 69, 74, 79, 84, 89, 94, 99, 104, 109, 114, 119, 124, 129, 134, 139, 144, 149, 154, 159, 164, 169, 174, 179, 184, 189, 194, 199, 204, 209, 214, 219, 224, 229, 234, 239, 244, 249, 254, 259, 264, 269, 274, 279, 284, 289, 294, 299]
train:
   restore_file:
     - ../bfit_r2l/0/checkpoints/checkpoint100.pt
     - ../bfit_r2l/1/checkpoints/checkpoint100.pt
     - ../bfit_r2l/2/checkpoints/checkpoint100.pt
     - ../bfit_r2l/3/checkpoints/checkpoint100.pt
     - ../bfit_r2l/4/checkpoints/checkpoint100.pt
   seed_list: [4654, 9630, 27029, 38836, 46738]
   save_interval: 5
   max_epoch: 160
   update_freq: 4
   max_tokens: 4000
   arch: base
   dropout: 0.3
   attention_dropout: 0.2
   activation_dropout: 0.2
   lr: 0.0015
   warmup_updates: 8000
   clip_norm: 1.0
   weight_decay: 0.001
generate:
   r2l: true
   epoch:
      start: 105
      step: 5
   ensemble_max_tokens: 1000
score:
   await: true
   jobs: 10
rerank:
   with_tag: true
   r2l_path: ../bfit_r2l
   r2l_vocab: /home/koyama.s/korrektur/arbeitsplatz/data/bfit/bfit_r2l_16000/0/data-bin/dict.src.txt
   fm:
      mlm_arch_list:
         - bert-base-german-dbmdz-cased
   wf:
      mlm_arch_list:
         - roberta-large
   lambda: [0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, 0.225, 0.25, 0.275, 0.3]

